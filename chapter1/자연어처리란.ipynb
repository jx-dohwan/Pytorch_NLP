{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리란 무엇일까?\n",
    "- 자연어 처리 인공지능은 사람의 언어가 컴퓨터가 알아듣도록 처리하는 인터페이스 역할을 한다.\n",
    "- 따라서 자연어 처리 인공지능을 개발하려면 컴퓨터 공학뿐만 아니라 언어학 지식도 어느 정도 필요하다.\n",
    "- 이러한 자연어 처리의 최종 목표는 컴퓨터가 사람의 언어를 이해하고 여러 가지 문제를 수행할 수 있도록 하는 것이다.\n",
    "- 자연어 처리 기술에 의해 수행되는 대표적인 과제 또는 응용 분야는 다음과 같다.\n",
    "    - 감성분석(sentiment analysis)과 같이 대량의 텍스트를 이해하고 수치화하는 작업\n",
    "    - 애플의 시리, 아마존의 알렉사와 같은 서비스를 통해 사용자의 의도를 파악하고 대화하거나 도움을 주는 작업\n",
    "    - 요약(summarization), 기계번역(machine translation)과 같은 작업\n",
    "    - 사용자로부터 입력을 받아 사용자가 원하는 것을 검색 및 답변을 주는 작업"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 소개\n",
    "- 자연어 처리는 단어간의 순서 및 상호 정보가 반영된 시퀀셜 데이터라는 점이 큰 장벅이었다.\n",
    "- 하지만 결국엔 어텐션 메커니즘의 등장으로 인해서 요원해보이던 기계번역 분야마저 end-to-end방식의 딥러닝에 의해 정복되었다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝의 역사\n",
    "#### 2010년 이전\n",
    "- 인공지능은 지금까지 두번의 대유행이 있었고 그에 따른 두번의 빙하기가 있었다.\n",
    "- 1950년대에 이어 두 번째 황금기였던 1980년대에 역전파 알고리즘이 제안된 후 기존의 문제는 해결된 듯 보였다.\n",
    "- 그러나 다시 여러 한계점을 드러내며 두 번째 침체기를 맞이했다.\n",
    "-  2006년에 심층 신뢰 신경망을 통해 여러 층의 은닉층을 효과적으로 사전훈련 시킬 방법을 제시했다.\n",
    "#### 이미지 분류\n",
    "- 2012년 이미지넷에서 인공 신경망을 이용한 AlexNet은 경쟁자들을 큰 차이로 따돌리고 우승하며 딥러닝의 시대의 서막을 올린다.\n",
    "- AlexNet은 여러 층의 합성곱 계층을 쌓아서 네트워크 구조를 만들며 기존 우승자들과 확연한 실력 차를 보여주었다.\n",
    "- 이후 딥러닝의 경연장이 된 이미지넷 대회에서는 거의 모든 참가자가 딥러닝을 이용하여 알고리즘을 구현하였다.\n",
    "- 2015년에는 ResNet이 레지듀얼 커넥션을 활용하여 150층이 넘는 깊은 네트워크를 구성하여 우승하였다.\n",
    "- 하지만 실생활에서의 이미지 분류 문제는 아직 어려움이 남아있다.\n",
    "#### 음성 인식\n",
    "- 2012년 GMM을 DNN으로 대체하여 수십년 간의 정체를 단숨에 뛰어 넘는 큰 혁명을 맞이하게 된다.\n",
    "- 영상처리와 자연어 처리에서 모두 보이는 익숙한 패턴이다.\n",
    "- 그리고 점차 음향 모델 전체를 LSTM으로 대체하고 결국에는 end-to-end 방식이 성과를 내고 자리잡는 추세이다.\n",
    "#### 기계번역\n",
    "- 2014년 seq2seq라는 모델 구조가 소개되며 end-to-end신경망 기반 기계 번역의 시대가 열리게 되었다.\n",
    "- seq2seq를 기반으로 어텐션 메커니즘이 제안되며 결국 기계번역은 신경망 기계번역으로 대통합이 이루어졌다..\n",
    "- 현재 상용 기계번역 시스템은 모두 딥러닝에 의한 시스템으로 대체 되었다.\n",
    "#### 생성 모델 학습\n",
    "- 적대적 학습이나 변분 오토인코더등이 주목받게 되었다.\n",
    "- 지금은 디퓨전이 나왔다.\n",
    "- 생성 모델은 레이블을 찾아내는 것이 아니라 데이터 분포 자체를 배우는 것에 집중하는 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리는 왜 어려울까?\n",
    "- 모호성\n",
    "- 다양한 표현\n",
    "- 불연속적인 데이터\n",
    "    - 차원의 저주 \n",
    "    - 노이즈와 정규화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무엇이 한국어 자연어 처리를 더욱 어렵게 만들까?\n",
    "- 교착어\n",
    "    - 한국어는 교착어에 속한다. 어근에 접사가 뭍어 의미와 문법적 기능이 부여된다.\n",
    "    - 다양한 파생이 가능\n",
    "    - 또한 접사가 붙어 같은 단어가 다양하게 생겨나므로 하나의 어근에서 비롯된 비슷한 의미의 단어가 매우 많이 생성\n",
    "    - 접사에 따라 단어의 역할이 정해지기 때문에 상대적으로 어순은 중요하지 않다.\n",
    "    - 분절을 통해 같은 어근에서 생겨난 단어를 처리해야한다.\n",
    "- 띄어쓰기\n",
    "    - 분절을 통해 띄어쓰기를 정제해주는 과정이 필요하다.\n",
    "- 평서문과 의문문\n",
    "    - 한국어는 의문문과 평서문이 같은 형태의 문장 구조를 가지고 있다.\n",
    "    - 따라서 마침표나 물음표가 붙지 않으면 알 수 없는 경우가 많다.\n",
    "- 주어 생략\n",
    "    - 영어는 명사가 중요하다 그래서 주어가 생략되는 경우는 거의 없다.\n",
    "    - 하지만 한국어는 동사를 중요시하고 대신 주어가 자주 생략된다.\n",
    "    - 기계번역을 비롯한 문장의 정확한 의미를 파악하기가 매우 어려워 진다.\n",
    "- 한자 기반의 언어\n",
    "    - 다른 언어에 비해 중의성 문제가 더 가중되어 버렸다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 처리의 최근추세(2019기준)\n",
    "\n",
    "## 자연어 생성의 시작\n",
    "- seq2seq의 발표에 이서 어텐션 기법이 개발되어 성공적으로 주어진 정보에 기반하여 자유롭게 문장을 생성하는 자연어 생성이 가능해 졌다.\n",
    "\n",
    "## 메모리를 활용한 심화 영ㄴ구\n",
    "- 메모리를 활용하는 기법을 메모리 증강 신경망이고 한다. 이 기법이 발전한다면 최종적으로 우리가 원하는 정보를 신경망을 통해 저장하고 필요할때 잘 조합하여 꺼내쓰는 QA와 같은 문제에 효울적으로 대응할 수 있을 것이다.\n",
    "\n",
    "## 강화학습의 자연어 처리 분야에 대한 성공적 적용\n",
    "- 강화학습의 플리시 그래디언트 방식을 자연어 생성에 성공적으로 적용함으로 적대적 학습과 같은 방법을 자연어 처리에서도 흉내낼 수 있게 되었다.\n",
    "- 이 처럼 강화학습을 사용하여 실제 자연어 생성의 목적 함수로터 보상을 받을 수 있게 되자 훨씬 실제 사람이 사용하는 듯한 문장을 생성해내는 능력을 더욱 극대화할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
